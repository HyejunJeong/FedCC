{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ff8712-121e-4c55-9b57-eb317f36a195",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plan\n",
    "\n",
    "- [x] FL base framework\n",
    "- [x] implement non-iid sampling function following dirichlet dist\n",
    "\n",
    "#### Attack simulation\n",
    "- [ ] untargeted model poisoning\n",
    "    - Local model poisoning attacks to Byzantine-robust federated learning <br>\n",
    "    https://github.com/vrt1shjwlkr/NDSS21-Model-Poisoning fang attack <br>\n",
    "    krum-attack, trimmed-mean/median attack\n",
    "- [ ] targeted model poisoning\n",
    "    - Analyzing federated learning through an adversarial lens <br>\n",
    "    https://github.com/inspire-group/ModelPoisoning\n",
    "- [ ] data poisoning\n",
    "    - DBA: Distributed backdoor attacks against federated learning <br>\n",
    "    https://github.com/AI-secure/DBA\n",
    "    \n",
    "#### Defense baseline\n",
    "- [x] FedAvg\n",
    "- [x] Krum\n",
    "- [x] Multi-Krum\n",
    "- [x] Bulyan\n",
    "- [x] Coordinate median\n",
    "- [ ] FoolsGold\n",
    "- [ ] FLARE\n",
    "\n",
    "#### Proposed method\n",
    "- [ ] hypersphere uniformity loss as loss function\n",
    "- [ ] extract PLRs\n",
    "- [ ] apply RBF hypersphere CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97834e9-666d-4e4a-a15e-332181ee70bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b6317-eed6-4f02-a94e-987e4061ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference, mal_inference\n",
    "from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar\n",
    "from utils import get_dataset, get_mal_dataset, exp_details, flatten, construct_ordered_dict\n",
    "from aggregate import fedavg, multi_krum, krum, coomed, bulyan, tr_mean, fed_align, fed_cka\n",
    "from attacks import get_malicious_updates_untargeted_mkrum, get_malicious_updates_untargeted_med, get_malicious_updates_targeted\n",
    "from cka import linear_CKA, kernel_CKA\n",
    "# python src/federated_main.py --model=cnn --dataset=cifar --gpu=0 --iid=1 --epochs=10\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e5affa-9f28-4dad-99af-52f285107603",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mkrum' from 'aggregate' (C:\\Users\\user\\Documents\\FL\\src\\aggregate.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLP, CNNMnist, CNNFashion_Mnist, CNNCifar\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataset, get_mal_dataset, exp_details, flatten\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maggregate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fedavg, mkrum, coomed, bulyan, flare\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mattacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_malicious_updates_untargeted_mkrum, get_malicious_updates_untargeted_med\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'mkrum' from 'aggregate' (C:\\Users\\user\\Documents\\FL\\src\\aggregate.py)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference, mal_inference\n",
    "from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar\n",
    "from utils import get_dataset, get_mal_dataset, exp_details, flatten\n",
    "from aggregate import fedavg, krum, multi_krum, coomed, bulyan, flare\n",
    "from attacks import get_malicious_updates_untargeted_mkrum, get_malicious_updates_untargeted_med\n",
    "\n",
    "# python src/federated_main.py --model=cnn --dataset=cifar --gpu=0 --iid=1 --epochs=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80c63c-85e6-433f-b354-b8656f3a2539",
   "metadata": {},
   "source": [
    "# ATTACK FREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea6ac2c-32ca-417f-90fb-f5b58b7ad1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    \n",
    "    # federated parameters (default values are set)\n",
    "    epochs = 20\n",
    "    num_users = 10\n",
    "    frac = 1 # fraction of clients\n",
    "    local_ep = 5 # num of local epoch\n",
    "    local_bs = 128 # batch size\n",
    "    lr = 0.001\n",
    "    momentum = 0.9\n",
    "    aggregation = 'coomed' # fedavg, krum, mkrum, coomed, bulyan, flare\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num = 9 # num of each kind of kernel\n",
    "    kernel_sizes = '3,4,5' # comma-separated kernel size to use for convolution\n",
    "    num_channels = 1 # num of channels of imgs\n",
    "    norm = 'batch_norm' # batch_norm, layer_norm, None\n",
    "    num_filters = 32 # num of filters for conv nets -- 32 for mini-imagenet, 64 for omiglot\n",
    "    max_pool = 'True' # whether use max pooling rather than strided convolutions\n",
    "    \n",
    "    # other arguments\n",
    "    dataset = \"fmnist\"\n",
    "    num_classes = 10 \n",
    "    gpu = 0\n",
    "    optimizer = 'adam'\n",
    "    iid = 1 # 0 for non-iid\n",
    "    alpha = 0.2 # noniid --> (0, 1] <-- iid\n",
    "    unequal = 0 # whether to use unequal data splits for non-iid settings (0 for equal splits)\n",
    "    stopping_rounds = 10 # rounds of early stopping\n",
    "    verbose = 0\n",
    "    seed = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd3f0dc-0c6d-402c-89a9-d0fd89853d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from cka import linear_CKA, kernel_CKA\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "\n",
    "flat_weights = malicious_grads\n",
    "second_last_layer = list(local_weights[0].keys())[-4]\n",
    "glob_plr = global_weights[second_last_layer]            \n",
    "structured_local_weights = [construct_ordered_dict(global_model, flat_weights) for flat_weights in malicious_grads]\n",
    "plrs = [(each_local[second_last_layer]) for each_local in structured_local_weights]\n",
    "\n",
    "num_clients = len(plrs)\n",
    "kernel_cka_vals = []\n",
    "align_loss_vals = []\n",
    "glob_plr = glob_plr.detach().cpu()\n",
    "\n",
    "scaled_weights = []\n",
    "\n",
    "for i in range(len(plrs)):\n",
    "    kernel_cka_vals.append(kernel_CKA(glob_plr, plrs[i].detach().cpu()))\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(np.array(kernel_cka_vals).reshape(-1, 1))\n",
    "labels = kmeans.labels_\n",
    "counter = Counter(labels)\n",
    "print(counter)\n",
    "\n",
    "majority = 1\n",
    "minor = 0\n",
    "\n",
    "if (counter[0] >= counter[1]):\n",
    "    majority = 0\n",
    "    minor = 1\n",
    "\n",
    "selected_idx = np.where(labels == majority)\n",
    "selected_parameters = []\n",
    "\n",
    "#     for i in selected_idx:\n",
    "#         selected_parameters.append(flat_weights[i].cpu().detach().numpy())\n",
    "#     selected_parameters = torch.tensor(selected_parameters[0]).to('cuda:0')\n",
    "#     agg_weights = torch.mean(selected_parameters, dim=0)\n",
    "\n",
    "suspects = np.where(labels == minor)\n",
    "\n",
    "    \n",
    "for i in range(len(scale)):\n",
    "    if i in suspects:\n",
    "        scale[i] = 0\n",
    "    else: \n",
    "        scale[i] = 1/scale[i]\n",
    "\n",
    "print(scale)\n",
    "\n",
    "for i in range(len(plrs)):\n",
    "    selected_parameters.append(scale[i] * flat_weights[i].cpu().detach().numpy())\n",
    "selected_parameters = torch.tensor(np.array(selected_parameters)).to('cuda:0')\n",
    "agg_weights = torch.mean(selected_parameters, dim=0)\n",
    "# agg_weights = torch.median(selected_parameters, dim=0)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462f137-23d4-4d56-8de6-1012b0181ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "\n",
    "    # define paths\n",
    "    path_project = os.path.abspath('..')\n",
    "    logger = SummaryWriter('../logs')\n",
    "\n",
    "    args = Args()\n",
    "    exp_details(args)\n",
    "\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # load dataset and user groups\n",
    "    train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "\n",
    "    # BUILD MODEL\n",
    "    if args.model == 'cnn':\n",
    "        # Convolutional neural netork\n",
    "        if args.dataset == 'mnist':\n",
    "            global_model = CNNMnist(args=args)\n",
    "        elif args.dataset == 'fmnist':\n",
    "            global_model = CNNFashion_Mnist(args=args)\n",
    "        elif args.dataset == 'cifar':\n",
    "            global_model = CNNCifar(args=args)\n",
    "\n",
    "    elif args.model == 'mlp':\n",
    "        # Multi-layer preceptron\n",
    "        img_size = train_dataset[0][0].shape\n",
    "        len_in = 1\n",
    "        for x in img_size:\n",
    "            len_in *= x\n",
    "            global_model = MLP(dim_in=len_in, dim_hidden=64, dim_out=args.num_classes)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "\n",
    "    # Set the model to train and send it to device.\n",
    "    global_model.to(device)\n",
    "    global_model.train()\n",
    "    print(global_model)\n",
    "\n",
    "    # copy weights\n",
    "    global_weights = global_model.state_dict()\n",
    "\n",
    "    # Training\n",
    "    train_loss, train_accuracy = [], []\n",
    "    val_acc_list, net_list = [], []\n",
    "    cv_loss, cv_acc = [], []\n",
    "    print_every = 1\n",
    "    val_loss_pre, counter = 0, 0\n",
    "\n",
    "    mal_user = False\n",
    "    \n",
    "    for epoch in tqdm(range(args.epochs)):\n",
    "        local_weights, local_losses = [], []\n",
    "        print('=========================================')\n",
    "        print(f'| Global Training Round : {epoch+1} |')\n",
    "        print('=========================================')\n",
    "\n",
    "        global_model.train()\n",
    "        m = max(int(args.frac * args.num_users), 1)\n",
    "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "\n",
    "        flattened_local_weights = []\n",
    "        \n",
    "        for idx in idxs_users:\n",
    "            local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[idx], logger=logger)\n",
    "            w, loss = local_model.update_weights(model=copy.deepcopy(global_model), global_round=epoch)\n",
    "            \n",
    "            # get new model\n",
    "            new_model = copy.deepcopy(global_model)\n",
    "            new_model.load_state_dict(w)\n",
    "            acc, _ = local_model.inference(model=new_model)\n",
    "            print('user {}, loss {.2f}, acc {.2f}'.format(idx, loss, 100*acc))\n",
    "            \n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(copy.deepcopy(loss))\n",
    "            # flatten the local weight (list of ordereddict to a tensor of lists)\n",
    "            flattened_local_weights.append(flatten(w))\n",
    "        flattened_local_weights = torch.tensor(np.array(flattened_local_weights)).to(device)\n",
    "        ## ATTACK TAKES PLACE HERE    \n",
    "        \n",
    "        \n",
    "        # update global weights\n",
    "        if args.aggregation == 'fedavg':\n",
    "            agg_weights = fedavg(flattened_local_weights)\n",
    "        elif args.aggregation == 'krum':\n",
    "            agg_weights, krum_candidates = mkrum(flattened_local_weights, 0, multi_k=False)\n",
    "        elif args.aggregation == 'mkrum':\n",
    "            agg_weights, krum_candidates = mkrum(flattened_local_weights, 0, multi_k=True)\n",
    "        elif args.aggregation == 'coomed':\n",
    "            agg_weights = coomed(flattened_local_weights)\n",
    "        elif args.aggregation == 'bulyan':\n",
    "            agg_weights, bulyan_candidate = bulyan(flattened_local_weights, 0)\n",
    "        elif args.aggregation == 'flare':\n",
    "            agg_weights = flare(flattened_local_weights)\n",
    "        else:\n",
    "            raise ValueError('Unknown aggregation strategy: {}'.format(args.aggregation))\n",
    "\n",
    "            \n",
    "        # reshape the flattened global weights into the ordereddict\n",
    "        keys = global_model.state_dict().keys()\n",
    "        start_idx = 0\n",
    "        model_grads = []\n",
    "\n",
    "        for i, param in enumerate(global_model.parameters()):\n",
    "            param_ = agg_weights[start_idx:start_idx + len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx = start_idx + len(param.data.view(-1))\n",
    "            param_ = param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "            \n",
    "        global_weights = OrderedDict(dict(zip(keys, model_grads)))  \n",
    "        \n",
    "        # update global weights\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        loss_avg = sum(local_losses) / len(local_losses)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        # # Calculate avg training accuracy over all users at every epoch\n",
    "        # list_acc, list_loss = [], []\n",
    "        # global_model.eval()\n",
    "        # for c in range(args.num_users):\n",
    "        #     local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[c], logger=logger)\n",
    "        #     acc, loss = local_model.inference(model=global_model)\n",
    "        #     list_acc.append(acc)\n",
    "        #     list_loss.append(loss)\n",
    "        # train_accuracy.append(sum(list_acc)/len(list_acc))\n",
    "\n",
    "        \n",
    "        # print global training loss after every 'i' rounds\n",
    "        if (epoch+1) % print_every == 0:\n",
    "            print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
    "            print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "            test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "            print('\\nGlobal model Benign Test Accuracy: {:.2f}% '.format(100*val_acc))\n",
    "            if mal_user:\n",
    "                mal_acc, mal_loss, mal_out = mal_inference(args, global_model, test_dataset, mal_X_list, mal_Y)\n",
    "                print('Global model Malicious Accuracy: {:.2f}%, Malicious Loss: {:.2f} , Outputs: {}\\n'.format(100*mal_acc, mal_loss, mal_out))\n",
    "\n",
    "    # Test inference after completion of training\n",
    "    test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "\n",
    "    print(f' \\n Results after {args.epochs} global rounds of training:')\n",
    "    # print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "    print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
    "\n",
    "    # Saving the objects train_loss and train_accuracy:\n",
    "    file_name = '../save/objects/{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}].pkl'.\\\n",
    "        format(args.dataset, args.model, args.epochs, args.frac, args.iid, args.local_ep, args.local_bs)\n",
    "\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump([train_loss, train_accuracy], f)\n",
    "\n",
    "    print('\\n Total Run Time: {0:0.4f}'.format(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7918656-a35e-4e75-b92d-564cfb594c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa178cf-3730-4d48-9ab9-70b2db91bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280bbe84-5615-4ae0-8a0c-2eb42988a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PLOTTING (optional)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# Plot Loss curve\n",
    "plt.figure()\n",
    "plt.title('Training Loss vs Communication rounds')\n",
    "plt.plot(range(len(train_loss)), train_loss, color='r')\n",
    "plt.ylabel('Training loss')\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.savefig('../save/fed_{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}]_loss.png'.\n",
    "            format(args.dataset, args.model, args.epochs, args.frac,\n",
    "                   args.iid, args.local_ep, args.local_bs))\n",
    "\n",
    "# Plot Average Accuracy vs Communication rounds\n",
    "plt.figure()\n",
    "plt.title('Average Accuracy vs Communication rounds')\n",
    "plt.plot(range(len(train_accuracy)), train_accuracy, color='k')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.savefig('../save/fed_{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}]_acc.png'.\n",
    "            format(args.dataset, args.model, args.epochs, args.frac,\n",
    "                   args.iid, args.local_ep, args.local_bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61762571-fb22-4871-ac3d-44ae3d5caa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda113",
   "language": "python",
   "name": "cuda113"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
