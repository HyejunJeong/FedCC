{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ff8712-121e-4c55-9b57-eb317f36a195",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plan\n",
    "\n",
    "- [x] FL base framework\n",
    "- [x] implement non-iid sampling function following dirichlet dist\n",
    "\n",
    "#### Attack simulation\n",
    "- [x] untargeted model poisoning\n",
    "    - Local model poisoning attacks to Byzantine-robust federated learning <br>\n",
    "    https://github.com/vrt1shjwlkr/NDSS21-Model-Poisoning fang attack <br>\n",
    "    krum-attack, trimmed-mean/median attack\n",
    "- [x] targeted model poisoning\n",
    "    - Analyzing federated learning through an adversarial lens <br>\n",
    "    https://github.com/inspire-group/ModelPoisoning\n",
    "- [x] data poisoning\n",
    "    - DBA: Distributed backdoor attacks against federated learning <br>\n",
    "    https://github.com/AI-secure/DBA\n",
    "    \n",
    "#### Defense baseline\n",
    "- [x] FedAvg\n",
    "- [x] Krum\n",
    "- [x] Multi-Krum\n",
    "- [x] Bulyan\n",
    "- [x] Coordinate median\n",
    "- [x] FLARE\n",
    "\n",
    "#### Proposed method\n",
    "- [x] extract PLRs\n",
    "- [x] apply RBF hypersphere CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97834e9-666d-4e4a-a15e-332181ee70bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e5affa-9f28-4dad-99af-52f285107603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference, mal_inference\n",
    "from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar, Alexnet, modelC, LeNet5, GoogleNet\n",
    "from utils import get_dataset, get_mal_dataset, exp_details, flatten, construct_ordered_dict\n",
    "from aggregate import fedavg, multi_krum, krum, coomed, bulyan, tr_mean, fed_align, fed_cc, flare, fltrust\n",
    "from attacks import get_malicious_updates_untargeted_mkrum, get_malicious_updates_untargeted_med\n",
    "\n",
    "# python src/federated_main.py --model=cnn --dataset=cifar --gpu=0 --iid=1 --epochs=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80c63c-85e6-433f-b354-b8656f3a2539",
   "metadata": {},
   "source": [
    "# Untargeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea6ac2c-32ca-417f-90fb-f5b58b7ad1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    \n",
    "    # federated parameters (default values are set)\n",
    "    epochs = 30\n",
    "    num_users = 10\n",
    "    frac = 1 # fraction of clients\n",
    "    local_ep = 5 # num of local epoch\n",
    "    local_bs = 100 # batch size\n",
    "    lr = 0.001\n",
    "    momentum = 0.9\n",
    "    aggregation = 'mkrum' # fedavg, krum, coomed, bulyan, flare, fedcc\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num = 9 # num of each kind of kernel\n",
    "    kernel_sizes = '3,4,5' # comma-separated kernel size to use for convolution\n",
    "    # num_channels = 1 # num of channels of imgs\n",
    "    norm = 'batch_norm' # batch_norm, layer_norm, None\n",
    "    num_filters = 32 # num of filters for conv nets -- 32 for mini-imagenet, 64 for omiglot\n",
    "    max_pool = 'True' # whether use max pooling rather than strided convolutions\n",
    "    \n",
    "    # other arguments\n",
    "    dataset = 'cifar100' # fmnist, cifar, cifar100\n",
    "    \n",
    "    if dataset == 'cifar100':\n",
    "        num_classes = 100 \n",
    "        num_channels = 3 # num of channels of imgs\n",
    "    else:\n",
    "        num_classes = 10\n",
    "        num_channels = 1\n",
    "\n",
    "    gpu = 0\n",
    "    optimizer = 'adam'\n",
    "    iid = 1 # 0 for non-iid\n",
    "    alpha = 1 # noniid --> (0, 100) <-- iid\n",
    "    unequal = 0 # whether to use unequal data splits for non-iid settings (0 for equal splits)\n",
    "    stopping_rounds = 10 # rounds of early stopping\n",
    "    verbose = 0\n",
    "    seed = 1\n",
    "\n",
    "    # malicious arguments\n",
    "    mal_clients = [3] # [#attacker] 0 for no attack\n",
    "    attack_type = 'untargeted_med'# untargeted_med, untargeted_mkrum\n",
    "    mal_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf111df3-2ff1-45f7-a22e-2cd055e6d6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "    Model     : cnn\n",
      "    Optimizer : adam\n",
      "    Learning  : 0.001\n",
      "    Aggregation     : mkrum\n",
      "    Global Rounds   : 30\n",
      "\n",
      "    Federated parameters:\n",
      "    IID\n",
      "    Fraction of users    : 1\n",
      "    Local Batch size     : 100\n",
      "    Local Epochs         : 5\n",
      "\n",
      "    Malicious parameters:\n",
      "    Attackers            : [3]\n",
      "    Attack Type          : untargeted_med\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "LeNet5(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=44944, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=100, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "| Global Training Round : 1 |\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjeong_umass_edu/.conda/envs/torchgpu/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 1 global rounds:\n",
      "Training Loss : 3.988388169663293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [14:31<7:01:15, 871.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 339.2744 val acc 6.1100\n",
      "\n",
      "Global model Benign Test Accuracy: 6.11% \n",
      "=========================================\n",
      "| Global Training Round : 2 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 2 global rounds:\n",
      "Training Loss : 3.457505524882248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [28:12<6:32:46, 841.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 285.9599 val acc 17.6500\n",
      "\n",
      "Global model Benign Test Accuracy: 17.65% \n",
      "=========================================\n",
      "| Global Training Round : 3 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 3 global rounds:\n",
      "Training Loss : 2.9129060383708705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [42:50<6:26:11, 858.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 333.4916 val acc 19.2300\n",
      "\n",
      "Global model Benign Test Accuracy: 19.23% \n",
      "=========================================\n",
      "| Global Training Round : 4 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 4 global rounds:\n",
      "Training Loss : 2.5431864137468594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [56:26<6:04:45, 841.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 364.3694 val acc 20.1100\n",
      "\n",
      "Global model Benign Test Accuracy: 20.11% \n",
      "=========================================\n",
      "| Global Training Round : 5 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 5 global rounds:\n",
      "Training Loss : 2.2605586678492173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [1:11:07<5:56:35, 855.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 391.2349 val acc 19.1600\n",
      "\n",
      "Global model Benign Test Accuracy: 19.16% \n",
      "=========================================\n",
      "| Global Training Round : 6 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 6 global rounds:\n",
      "Training Loss : 2.048563561382748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [1:24:41<5:36:41, 841.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 415.2630 val acc 19.2900\n",
      "\n",
      "Global model Benign Test Accuracy: 19.29% \n",
      "=========================================\n",
      "| Global Training Round : 7 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 7 global rounds:\n",
      "Training Loss : 1.8861761434357234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [1:38:53<5:23:53, 844.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 417.1126 val acc 18.7800\n",
      "\n",
      "Global model Benign Test Accuracy: 18.78% \n",
      "=========================================\n",
      "| Global Training Round : 8 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 8 global rounds:\n",
      "Training Loss : 1.758122733650463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [1:53:03<5:10:21, 846.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 428.5595 val acc 18.3700\n",
      "\n",
      "Global model Benign Test Accuracy: 18.37% \n",
      "=========================================\n",
      "| Global Training Round : 9 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 9 global rounds:\n",
      "Training Loss : 1.6462146736258672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [2:07:59<5:01:46, 862.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 444.4007 val acc 18.5000\n",
      "\n",
      "Global model Benign Test Accuracy: 18.50% \n",
      "=========================================\n",
      "| Global Training Round : 10 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 10 global rounds:\n",
      "Training Loss : 1.5475223061457677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [2:21:57<4:44:54, 854.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 471.7962 val acc 18.5800\n",
      "\n",
      "Global model Benign Test Accuracy: 18.58% \n",
      "=========================================\n",
      "| Global Training Round : 11 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 11 global rounds:\n",
      "Training Loss : 1.4745535233458988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [2:35:56<4:29:07, 849.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 454.7426 val acc 18.2400\n",
      "\n",
      "Global model Benign Test Accuracy: 18.24% \n",
      "=========================================\n",
      "| Global Training Round : 12 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 12 global rounds:\n",
      "Training Loss : 1.4076850696562213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [2:50:05<4:14:49, 849.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 473.4179 val acc 17.9500\n",
      "\n",
      "Global model Benign Test Accuracy: 17.95% \n",
      "=========================================\n",
      "| Global Training Round : 13 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 13 global rounds:\n",
      "Training Loss : 1.3424336978703595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [3:04:01<3:59:31, 845.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 491.3758 val acc 18.3000\n",
      "\n",
      "Global model Benign Test Accuracy: 18.30% \n",
      "=========================================\n",
      "| Global Training Round : 14 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 14 global rounds:\n",
      "Training Loss : 1.2918311223953878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [3:17:52<3:44:18, 841.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 480.3299 val acc 18.0300\n",
      "\n",
      "Global model Benign Test Accuracy: 18.03% \n",
      "=========================================\n",
      "| Global Training Round : 15 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 15 global rounds:\n",
      "Training Loss : 1.2425081628400256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [3:31:37<3:29:02, 836.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 511.3776 val acc 18.0900\n",
      "\n",
      "Global model Benign Test Accuracy: 18.09% \n",
      "=========================================\n",
      "| Global Training Round : 16 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 16 global rounds:\n",
      "Training Loss : 1.1955007977613215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [3:46:35<3:19:26, 854.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 511.6167 val acc 17.8200\n",
      "\n",
      "Global model Benign Test Accuracy: 17.82% \n",
      "=========================================\n",
      "| Global Training Round : 17 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 17 global rounds:\n",
      "Training Loss : 1.153247471217148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [4:00:41<3:04:39, 852.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 521.9863 val acc 17.3300\n",
      "\n",
      "Global model Benign Test Accuracy: 17.33% \n",
      "=========================================\n",
      "| Global Training Round : 18 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 18 global rounds:\n",
      "Training Loss : 1.1140644122068843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [4:14:59<2:50:48, 854.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 523.9157 val acc 17.5300\n",
      "\n",
      "Global model Benign Test Accuracy: 17.53% \n",
      "=========================================\n",
      "| Global Training Round : 19 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 19 global rounds:\n",
      "Training Loss : 1.0828571520198513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [4:28:44<2:34:57, 845.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 505.1465 val acc 17.0700\n",
      "\n",
      "Global model Benign Test Accuracy: 17.07% \n",
      "=========================================\n",
      "| Global Training Round : 20 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 20 global rounds:\n",
      "Training Loss : 1.052730077682146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [4:45:13<2:28:05, 888.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 519.8961 val acc 17.4200\n",
      "\n",
      "Global model Benign Test Accuracy: 17.42% \n",
      "=========================================\n",
      "| Global Training Round : 21 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 21 global rounds:\n",
      "Training Loss : 1.0258262578342552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [4:59:38<2:12:11, 881.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 524.3985 val acc 17.0900\n",
      "\n",
      "Global model Benign Test Accuracy: 17.09% \n",
      "=========================================\n",
      "| Global Training Round : 22 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 22 global rounds:\n",
      "Training Loss : 1.0004843378420871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [5:12:46<1:53:46, 853.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 523.9314 val acc 17.2000\n",
      "\n",
      "Global model Benign Test Accuracy: 17.20% \n",
      "=========================================\n",
      "| Global Training Round : 23 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 23 global rounds:\n",
      "Training Loss : 0.9752814795584807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [5:26:08<1:37:46, 838.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 528.7131 val acc 17.3800\n",
      "\n",
      "Global model Benign Test Accuracy: 17.38% \n",
      "=========================================\n",
      "| Global Training Round : 24 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 24 global rounds:\n",
      "Training Loss : 0.9501997419906824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [5:39:29<1:22:41, 826.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 540.5860 val acc 16.9800\n",
      "\n",
      "Global model Benign Test Accuracy: 16.98% \n",
      "=========================================\n",
      "| Global Training Round : 25 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 25 global rounds:\n",
      "Training Loss : 0.9309947893751519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [5:52:44<1:08:07, 817.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 525.2994 val acc 17.2800\n",
      "\n",
      "Global model Benign Test Accuracy: 17.28% \n",
      "=========================================\n",
      "| Global Training Round : 26 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 26 global rounds:\n",
      "Training Loss : 0.9119067911288808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [6:05:37<53:35, 803.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 531.7744 val acc 17.1100\n",
      "\n",
      "Global model Benign Test Accuracy: 17.11% \n",
      "=========================================\n",
      "| Global Training Round : 27 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 27 global rounds:\n",
      "Training Loss : 0.8921581876143768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [6:18:41<39:54, 798.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 543.5930 val acc 17.1900\n",
      "\n",
      "Global model Benign Test Accuracy: 17.19% \n",
      "=========================================\n",
      "| Global Training Round : 28 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 28 global rounds:\n",
      "Training Loss : 0.8750729751867024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [6:32:35<26:57, 808.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 537.5212 val acc 16.8500\n",
      "\n",
      "Global model Benign Test Accuracy: 16.85% \n",
      "=========================================\n",
      "| Global Training Round : 29 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 29 global rounds:\n",
      "Training Loss : 0.8575255416814705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [6:47:44<13:58, 838.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 529.7231 val acc 16.5000\n",
      "\n",
      "Global model Benign Test Accuracy: 16.50% \n",
      "=========================================\n",
      "| Global Training Round : 30 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 30 global rounds:\n",
      "Training Loss : 0.8401157678234767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [6:58:20<00:00, 836.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 540.1229 val acc 16.5200\n",
      "\n",
      "Global model Benign Test Accuracy: 16.52% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Results after 30 global rounds of training:\n",
      "|---- Test Accuracy: 16.52%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "\n",
    "    # define paths\n",
    "    path_project = os.path.abspath('..')\n",
    "    logger = SummaryWriter('../logs')\n",
    "\n",
    "    args = Args()\n",
    "    exp_details(args)\n",
    "\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    for n_attacker in args.mal_clients:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # load dataset and user groups\n",
    "        train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "\n",
    "        # BUILD MODEL\n",
    "        if args.model == 'cnn':\n",
    "            # Convolutional neural netork\n",
    "            if args.dataset == 'mnist':\n",
    "                global_model = CNNMnist(args=args)\n",
    "            elif args.dataset == 'fmnist':\n",
    "                global_model = CNNFashion_Mnist(args=args)\n",
    "            elif args.dataset == 'cifar':\n",
    "                global_model = CNNCifar(args=args)\n",
    "            elif args.dataset == 'cifar100':\n",
    "                global_model = LeNet5(args=args)\n",
    "\n",
    "        elif args.model == 'mlp':\n",
    "            # Multi-layer preceptron\n",
    "            img_size = train_dataset[0][0].shape\n",
    "            len_in = 1\n",
    "            for x in img_size:\n",
    "                len_in *= x\n",
    "                global_model = MLP(dim_in=len_in, dim_hidden=64, dim_out=args.num_classes)\n",
    "        else:\n",
    "            exit('Error: unrecognized model')\n",
    "\n",
    "        # Set the model to train and send it to device.\n",
    "        global_model.to(device)\n",
    "        global_model.train()\n",
    "        print(global_model)\n",
    "\n",
    "        # copy weights\n",
    "        global_weights = global_model.state_dict()\n",
    "\n",
    "        # Training\n",
    "        train_loss, train_accuracy = [], []\n",
    "        val_acc_list, net_list = [], []\n",
    "        cv_loss, cv_acc = [], []\n",
    "        print_every = 1\n",
    "        val_loss_pre, counter = 0, 0\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(args.epochs)):\n",
    "            local_weights, local_losses = [], []\n",
    "            print('=========================================')\n",
    "            print(f'| Global Training Round : {epoch+1} |')\n",
    "            print('=========================================')\n",
    "\n",
    "            global_model.train()\n",
    "            # m = max(int(args.frac * args.num_users), 1)\n",
    "            # idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "\n",
    "            flattened_local_weights = []\n",
    "\n",
    "            \n",
    "            m = max(int(args.frac * args.num_users), 1)\n",
    "            idxs_users = np.random.choice(range(args.num_users), (m - args.mal_clients[0]), replace=False)\n",
    "\n",
    "            for idx in idxs_users:\n",
    "                local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[idx], logger=logger)\n",
    "                w, loss = local_model.update_weights(model=copy.deepcopy(global_model), global_round=epoch)\n",
    "                \n",
    "                local_weights.append(copy.deepcopy(w))\n",
    "                local_losses.append(copy.deepcopy(loss))\n",
    "                \n",
    "                # # get new model\n",
    "                # new_model = copy.deepcopy(global_model)\n",
    "                # new_model.load_state_dict(w)\n",
    "                # acc, _ = local_model.inference(model=new_model)\n",
    "                # print('user {}, loss {:.2f}, acc {:.2f}'.format(idx, loss, 100*acc))\n",
    "\n",
    "                # flatten the local weight (list of ordereddict to a tensor of lists)\n",
    "                flattened_local_weights.append(flatten(w))\n",
    "            flattened_local_weights = torch.tensor(np.array(flattened_local_weights)).to(device)\n",
    "            \n",
    "            malicious_grads = flattened_local_weights\n",
    "            \n",
    "            if n_attacker > 0:\n",
    "                \n",
    "                # Fang attacks (untargeted MPA on mkrum and med)\n",
    "                # agg_grads = torch.mean(malicious_grads, 0)\n",
    "                agg_grads = torch.tensor(flatten(global_weights)).to(device)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                \n",
    "                if args.attack_type == 'untargeted_mkrum':\n",
    "                    malicious_grads = get_malicious_updates_untargeted_mkrum(malicious_grads, agg_grads, deviation, n_attacker)\n",
    "                    \n",
    "                elif args.attack_type == 'untargeted_med':\n",
    "                    malicious_grads = get_malicious_updates_untargeted_med(malicious_grads, deviation, n_attacker)\n",
    "\n",
    "            print(len(malicious_grads),len(flattened_local_weights), n_attacker)\n",
    "            \n",
    "            # update global weights\n",
    "            if args.aggregation == 'fedavg':\n",
    "                agg_weights = fedavg(malicious_grads)\n",
    "            elif args.aggregation == 'krum':\n",
    "                agg_weights, selected_idxs = krum(malicious_grads, n_attacker)\n",
    "            elif args.aggregation == 'mkrum':\n",
    "                agg_weights, selected_idxs = multi_krum(malicious_grads, n_attacker)\n",
    "            elif args.aggregation == 'coomed':\n",
    "                agg_weights = coomed(malicious_grads)\n",
    "            elif args.aggregation == 'bulyan':\n",
    "                agg_weights, selected_idxs = bulyan(malicious_grads, n_attacker)\n",
    "            elif args.aggregation == 'trmean':\n",
    "                agg_weights = tr_mean(malicious_grads, n_attacker)\n",
    "            elif args.aggregation == 'fltrust':\n",
    "                glob_weights = []\n",
    "                glob_weights.append(flatten(global_weights))\n",
    "                agg_weights = fltrust(malicious_grads, glob_weights)\n",
    "\n",
    "            elif args.aggregation == 'flare':\n",
    "                second_last_layer = list(local_weights[0].keys())[-4]\n",
    "                structured_local_weights = [construct_ordered_dict(global_model, flat_weights) for flat_weights in malicious_grads]\n",
    "                plrs = [(each_local[second_last_layer]) for each_local in structured_local_weights]\n",
    "                agg_weights, count_dict = flare(malicious_grads, plrs)\n",
    "                print(f'flare count_dict: {count_dict}')\n",
    "\n",
    "            elif args.aggregation == 'fedcc':\n",
    "                # second_last_layer = list(local_weights[0].keys())[-6]\n",
    "                second_last_layer = list(local_weights[0].keys())[-4]\n",
    "                glob_plr = global_weights[second_last_layer]\n",
    "                # glob_plr = glob_plr.reshape((glob_plr.shape[0]*glob_plr.shape[2], glob_plr.shape[1]*glob_plr.shape[3]))\n",
    "                structured_local_weights = [construct_ordered_dict(global_model, flat_weights) for flat_weights in malicious_grads]\n",
    "                plrs = [(each_local[second_last_layer].reshape((glob_plr.shape[0], glob_plr.shape[1]))) for each_local in structured_local_weights]\n",
    "                agg_weights, selected_idxs = fed_cc(local_weights, glob_plr, 'kernel')\n",
    "                print(f'fed_cc Selected idx: {selected_idxs}')\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Unknown aggregation strategy: {}'.format(args.aggregation))\n",
    "\n",
    "\n",
    "            # reshape the flattened global weights into the ordereddict\n",
    "            global_weights = construct_ordered_dict(global_model, agg_weights)\n",
    "\n",
    "            # update global weights\n",
    "            global_model.load_state_dict(global_weights)\n",
    "\n",
    "            loss_avg = sum(local_losses) / len(local_losses)\n",
    "            train_loss.append(loss_avg)\n",
    "\n",
    "            # # Calculate avg training accuracy over all users at every epoch\n",
    "            # list_acc, list_loss = [], []\n",
    "            # global_model.eval()\n",
    "            # for c in range(args.num_users):\n",
    "            #     local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[c], logger=logger)\n",
    "            #     acc, loss = local_model.inference(model=global_model)\n",
    "            #     list_acc.append(acc)\n",
    "            #     list_loss.append(loss)\n",
    "            # train_accuracy.append(sum(list_acc)/len(list_acc))\n",
    "\n",
    "            # print global training loss after every 'i' rounds\n",
    "            if (epoch+1) % print_every == 0:\n",
    "                print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
    "                print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "                test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "                \n",
    "                print('%s: %s n_attacker %d fed_model val loss %.4f val acc %.4f' \\\n",
    "                      %(args.aggregation, args.attack_type, n_attacker, test_loss, 100*test_acc))\n",
    "                print('\\nGlobal model Benign Test Accuracy: {:.2f}% '.format(100*test_acc))\n",
    "                \n",
    "    # Test inference after completion of training\n",
    "    test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "\n",
    "    print(f' \\n Results after {args.epochs} global rounds of training:')\n",
    "    # print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "    print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
    "\n",
    "#     # Saving the objects train_loss and train_accuracy:\n",
    "#     file_name = '../save/objects/{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}].pkl'.\\\n",
    "#         format(args.dataset, args.model, args.epochs, args.frac, args.iid, args.local_ep, args.local_bs)\n",
    "\n",
    "#     with open(file_name, 'wb') as f:\n",
    "#         pickle.dump([train_loss, train_accuracy], f)\n",
    "\n",
    "#     print('\\n Total Run Time: {0:0.4f}'.format(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5491ef35-3a03-43ec-9732-88a307925d61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mk\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2738322-8c26-4b04-bdf3-5cef8c4a7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_weights = []\n",
    "for key in global_weights:\n",
    "    if 'weight' in key:\n",
    "        only_weights = np.append(only_weights, global_weights[key].detach().cpu().numpy())\n",
    "_, glob_svd, _, = np.linalg.svd(only_weights.reshape(1,-1))\n",
    "glob_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db2a391-1ea5-439d-b07d-f462c4c47c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "sim_vals = []\n",
    "glob_plr = glob_plr.detach().cpu()\n",
    "\n",
    "print('euclidean')\n",
    "for i in range(len(plrs)):\n",
    "    val = euclidean_distances(glob_plr.reshape(1, -1), plrs[i].detach().cpu().reshape(1,-1))[0][0]\n",
    "    # print(val)\n",
    "    if np.isnan(val):\n",
    "        sim_vals.append(0)\n",
    "    else:\n",
    "        sim_vals.append(val)\n",
    "print(sim_vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce6102-937b-42f8-8b03-476a3b9ad91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, paired_cosine_distances\n",
    "\n",
    "sim_vals = []\n",
    "glob_plr = glob_plr.detach().cpu()\n",
    "\n",
    "print('cosine')\n",
    "for i in range(len(plrs)):\n",
    "    val = cosine_similarity(glob_plr.reshape(1, -1), plrs[i].detach().cpu().reshape(1,-1))[0][0]\n",
    "    if np.isnan(val):\n",
    "        sim_vals.append(0)\n",
    "    else:\n",
    "        sim_vals.append(val)\n",
    "print(sim_vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1caf9b2-dfe6-4dcf-b3e5-d7b47e3fe1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_local_weights = [construct_ordered_dict(global_model, flat_weights) for flat_weights in malicious_grads]\n",
    "\n",
    "conv1_weights = [np.array(w['conv1.weight'].detach().cpu().reshape(-1)) for w in structured_local_weights]\n",
    "conv1_weights = np.array(conv1_weights)\n",
    "conv2_weights = [np.array(w['conv2.weight'].detach().cpu().reshape(-1)) for w in structured_local_weights]\n",
    "conv2_weights = np.array(conv2_weights)\n",
    "conv3_weights = [np.array(w['conv3.weight'].detach().cpu().reshape(-1)) for w in structured_local_weights]\n",
    "conv3_weights = np.array(conv3_weights)\n",
    "fc1_weights = [np.array(w['fc1.weight'].detach().cpu().reshape(-1)) for w in structured_local_weights]\n",
    "fc1_weights = np.array(fc1_weights)\n",
    "fc2_weights = [np.array(w['fc2.weight'].detach().cpu().reshape(-1)) for w in structured_local_weights]\n",
    "fc2_weights = np.array(fc2_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3119c9-cf33-44a5-a304-5d92f65a073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5\n",
    "\n",
    "_, s_layer_0, _, = np.linalg.svd(conv1_weights)\n",
    "_, s_layer_1, _, = np.linalg.svd(conv2_weights)\n",
    "_, s_layer_2, _, = np.linalg.svd(conv3_weights)\n",
    "_, s_layer_3, _, = np.linalg.svd(fc1_weights)\n",
    "_, s_layer_4, _, = np.linalg.svd(fc2_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b74fb-9c4b-411c-b1bc-544a40eecedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba014d74-03d8-49b4-9655-7fc6935e4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(np.arange(len(s_layer_0)), [s_layer_0, s_layer_1, s_layer_2, s_layer_3, s_layer_4]):\n",
    "    print(x, y)\n",
    "    plt.scatter([x], y[x], cmap='copper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc653a-7218-468a-915e-c36621cc6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x, y in zip(np.arange(num_layers), [s_layer_0, s_layer_1, s_layer_2, s_layer_3, s_layer_4]):\n",
    "    plt.scatter([x]*len(s_layer_0), y, cmap=\"copper\")\n",
    "    for i, txt in enumerate(np.arange(len(s_layer_0))):\n",
    "        plt.annotate(txt, (x, y[i]))\n",
    "    \n",
    "plt.xticks(np.arange(num_layers))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa995b0a-0c2b-47aa-9644-47a104ceb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from numpy import reshape\n",
    "import seaborn as sns\n",
    "import pandas as pd  \n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "conv1_scaled = scaler.fit_transform(conv1_weights)\n",
    "conv2_scaled = scaler.fit_transform(conv2_weights)\n",
    "conv3_scaled = scaler.fit_transform(conv3_weights)\n",
    "fc1_scaled = scaler.fit_transform(fc1_weights)\n",
    "fc2_scaled = scaler.fit_transform(fc2_weights)\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=5, n_iter=6000)\n",
    "conv1_z = (tsne.fit_transform(conv1_weights))\n",
    "conv2_z = (tsne.fit_transform(conv2_weights))\n",
    "conv3_z = (tsne.fit_transform(conv3_weights))\n",
    "fc1_z = (tsne.fit_transform(fc1_weights))\n",
    "fc2_z = (tsne.fit_transform(fc2_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51274d-8432-435f-94ec-bcba530468d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = conv1_z[:,0]\n",
    "comp2 = conv1_z[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f04ad0-9582-46ae-ac54-3ebd045d65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = conv2_z[:,0]\n",
    "comp2 = conv2_z[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eaf7e4-a91d-4966-8cdb-b1f24e7836a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = conv3_z[:,0]\n",
    "comp2 = conv3_z[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cda36e-dc28-4eec-98f0-d8bcce318d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = fc1_z[:,0]\n",
    "comp2 = fc1_z[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92d5fa-6847-4061-8f3b-8b00bf16bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = fc2_z[:,0]\n",
    "comp2 = fc2_z[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82710559-2c59-48d5-bcc6-5e14eb123102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ff5f3-aa56-4705-b664-39292e7a29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "conv1_scaled = scaler.fit_transform(conv1_weights)\n",
    "conv2_scaled = scaler.fit_transform(conv2_weights)\n",
    "conv3_scaled = scaler.fit_transform(conv3_weights)\n",
    "fc1_scaled = scaler.fit_transform(fc1_weights)\n",
    "fc2_scaled = scaler.fit_transform(fc2_weights)\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "conv1_k = (kmeans.fit_transform(conv1_scaled))\n",
    "conv2_k = (kmeans.fit_transform(conv2_scaled))\n",
    "conv3_k = (kmeans.fit_transform(conv3_scaled))\n",
    "fc1_k = (kmeans.fit_transform(fc1_scaled))\n",
    "fc2_k = (kmeans.fit_transform(fc2_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa187607-9dfa-4ae8-8af9-02fe4fd17688",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = conv1_k[:,0]\n",
    "comp2 = conv1_k[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2650d9f6-0dc2-443c-b6bd-d61ab3c976f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = conv2_k[:,0]\n",
    "comp2 = conv2_k[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90940b03-3d97-4ed8-acd0-04a5b6e12843",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = conv3_k[:,0]\n",
    "comp2 = conv3_k[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95e338-2620-4867-8ea8-8eb96117a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = fc1_k[:,0]\n",
    "comp2 = fc1_k[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774bb497-0888-42b2-a150-77c83e5549ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = fc2_k[:,0]\n",
    "comp2 = fc2_k[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=y, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca441a-bd05-4065-bba8-ad2062389984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b32cae7-97be-47f1-a1bc-daa0da2efc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "conv1_scaled = scaler.fit_transform(conv1_weights)\n",
    "conv2_scaled = scaler.fit_transform(conv2_weights)\n",
    "conv3_scaled = scaler.fit_transform(conv3_weights)\n",
    "fc1_scaled = scaler.fit_transform(fc1_weights)\n",
    "fc2_scaled = scaler.fit_transform(fc2_weights)\n",
    "\n",
    "\n",
    "dbscan = DBSCAN(eps=5, min_samples=1)\n",
    "\n",
    "conv1_d = (dbscan.fit_predict(conv1_scaled))\n",
    "conv2_d = (dbscan.fit_predict(conv2_scaled))\n",
    "conv3_d = (dbscan.fit_predict(conv3_scaled))\n",
    "fc1_d = (dbscan.fit_predict(fc1_scaled))\n",
    "fc2_d = (dbscan.fit_predict(fc2_scaled))\n",
    "\n",
    "# conv1_d = (dbscan.fit_predict(conv1_weights))\n",
    "# conv2_d = (dbscan.fit_predict(conv2_weights))\n",
    "# conv3_d = (dbscan.fit_predict(conv3_weights))\n",
    "# fc1_d = (dbscan.fit_predict(fc1_weights))\n",
    "# fc2_d = (dbscan.fit_predict(fc2_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ebb7e3-1f89-4b3f-bb95-f93b562d0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = conv1_scaled[:,0]\n",
    "comp2 = conv1_scaled[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=conv1_d, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d3655-4272-4e67-a579-4eb83999e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = conv2_scaled[:,0]\n",
    "comp2 = conv2_scaled[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=conv2_d, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb893155-2e7c-4663-8903-c69f283d7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = conv3_scaled[:,0]\n",
    "comp2 = conv3_scaled[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=conv3_d, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e8448-1d79-4c1a-b149-d9ab25c04476",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = fc1_scaled[:,0]\n",
    "comp2 = fc1_scaled[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=fc1_d, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ffbd9f-559e-42c8-a84a-c83495e0cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.arange(10)\n",
    "comp1 = fc2_scaled[:,0]\n",
    "comp2 = fc2_scaled[:,1]\n",
    "\n",
    "plt.scatter(comp1, comp2, c=fc2_d, cmap=plt.cm.get_cmap(\"jet\",10))\n",
    "plt.colorbar(ticks=range(10))\n",
    "\n",
    "for i, txt in enumerate(y):\n",
    "    plt.annotate(txt, (comp1[i], comp2[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f442595-4e71-481e-b039-4d64f428ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "linkage_data = linkage(conv1_weights, method='single', metric='correlation')\n",
    "dend = dendrogram(linkage_data)\n",
    "dend['dcoord']\n",
    "# plt.show()\n",
    "plt.title('Fang-Med-NIID: layer1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794d780-a6a4-4730-beb8-88986c75c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.027692341733213444-0.014671590015228997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992cb4d-1256-44dd-992e-2d14789ba632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linkage_data = linkage(conv2_weights, method='single', metric='correlation')\n",
    "dendrogram(linkage_data)['dcoord']\n",
    "plt.title('Fang-Med-NIID: layer2')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193db32a-fc93-4671-bce5-785b6ccaee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1364908196119804-0.035088486275514974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b0d41-20e1-493f-a5d8-e70bd76303ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linkage_data = linkage(conv3_weights, method='single', metric='correlation')\n",
    "dendrogram(linkage_data)['dcoord']\n",
    "plt.title('Fang-Med-NIID: layer3')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f172a-837f-472d-b7d8-efe581120d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.3123983411700274-0.04907789487647207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca95923-1565-48e5-8d6f-5062c3ee71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linkage_data = linkage(fc1_weights, method='single', metric='correlation')\n",
    "dendrogram(linkage_data)['dcoord']\n",
    "\n",
    "plt.title('Fang-Med-NIID: PLR')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9633a-23ad-428e-9654-552825513c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.4670590345070377-0.07906553072514055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca79074a-5544-476b-b49d-e0e1ffd5647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linkage_data = linkage(fc2_weights, method='single', metric='correlation')\n",
    "dendrogram(linkage_data)['dcoord']\n",
    "plt.title('Fang-Med-NIID: layer5')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a11a2e-c7be-407a-8339-abd7a6aedbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.08639369314601342-0.019640159432333104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c58776-4c4d-4884-a3ad-5b090cb8427e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61226598-762c-4db0-aa32-4a82e69ed4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.attack_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50253b-1047-4a71-bb88-4c313711fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27c5a8-f6b1-4da0-8488-70263a0315e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3316c-8811-41de-88a9-e84c0a36ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_details(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e3f4c-4fe2-4959-b7a7-f567db7c2a26",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
