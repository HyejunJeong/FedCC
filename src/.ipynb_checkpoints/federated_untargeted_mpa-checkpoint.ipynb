{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ff8712-121e-4c55-9b57-eb317f36a195",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "#### Attack simulation\n",
    "- [x] untargeted model poisoning\n",
    "    - Local model poisoning attacks to Byzantine-robust federated learning <br>\n",
    "    https://github.com/vrt1shjwlkr/NDSS21-Model-Poisoning fang attack <br>\n",
    "    krum-attack, trimmed-mean/median attack\n",
    "- [x] targeted model poisoning\n",
    "    - Analyzing federated learning through an adversarial lens <br>\n",
    "    https://github.com/inspire-group/ModelPoisoning\n",
    "- [x] data poisoning\n",
    "    - DBA: Distributed backdoor attacks against federated learning <br>\n",
    "    https://github.com/AI-secure/DBA\n",
    "    \n",
    "#### Defense baseline\n",
    "- [x] FedAvg\n",
    "- [x] Krum\n",
    "- [x] Multi-Krum\n",
    "- [x] Bulyan\n",
    "- [x] Coordinate median\n",
    "- [x] FLARE\n",
    "\n",
    "#### Proposed method\n",
    "- [x] extract PLRs\n",
    "- [x] apply RBF hypersphere CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97834e9-666d-4e4a-a15e-332181ee70bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e5affa-9f28-4dad-99af-52f285107603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference, mal_inference\n",
    "from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar, Alexnet, modelC, LeNet5, GoogleNet\n",
    "from utils import get_dataset, get_mal_dataset, exp_details, flatten, construct_ordered_dict\n",
    "from aggregate import fedavg, multi_krum, krum, coomed, bulyan, tr_mean, fed_align, fed_cc, flare, fltrust\n",
    "from attacks import get_malicious_updates_untargeted_mkrum, get_malicious_updates_untargeted_med\n",
    "\n",
    "# python src/federated_main.py --model=cnn --dataset=cifar --gpu=0 --iid=1 --epochs=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80c63c-85e6-433f-b354-b8656f3a2539",
   "metadata": {},
   "source": [
    "# Untargeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea6ac2c-32ca-417f-90fb-f5b58b7ad1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    \n",
    "    # federated parameters (default values are set)\n",
    "    epochs = 30\n",
    "    num_users = 10\n",
    "    frac = 1 # fraction of clients\n",
    "    local_ep = 5 # num of local epoch\n",
    "    local_bs = 100 # batch size\n",
    "    lr = 0.001\n",
    "    momentum = 0.9\n",
    "    aggregation = 'mkrum' # fedavg, krum, coomed, bulyan, flare, fedcc\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num = 9 # num of each kind of kernel\n",
    "    kernel_sizes = '3,4,5' # comma-separated kernel size to use for convolution\n",
    "    # num_channels = 1 # num of channels of imgs\n",
    "    norm = 'batch_norm' # batch_norm, layer_norm, None\n",
    "    num_filters = 32 # num of filters for conv nets -- 32 for mini-imagenet, 64 for omiglot\n",
    "    max_pool = 'True' # whether use max pooling rather than strided convolutions\n",
    "    \n",
    "    # other arguments\n",
    "    dataset = 'cifar100' # fmnist, cifar, cifar100\n",
    "    \n",
    "    if dataset == 'cifar100':\n",
    "        num_classes = 100 \n",
    "        num_channels = 3 # num of channels of imgs\n",
    "    else:\n",
    "        num_classes = 10\n",
    "        num_channels = 1\n",
    "\n",
    "    gpu = 0\n",
    "    optimizer = 'adam'\n",
    "    iid = 1 # 0 for non-iid\n",
    "    alpha = 1 # noniid --> (0, 100) <-- iid\n",
    "    unequal = 0 # whether to use unequal data splits for non-iid settings (0 for equal splits)\n",
    "    stopping_rounds = 10 # rounds of early stopping\n",
    "    verbose = 0\n",
    "    seed = 1\n",
    "\n",
    "    # malicious arguments\n",
    "    mal_clients = [3] # [#attacker] 0 for no attack\n",
    "    attack_type = 'untargeted_med'# untargeted_med, untargeted_mkrum\n",
    "    mal_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf111df3-2ff1-45f7-a22e-2cd055e6d6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "    Model     : cnn\n",
      "    Optimizer : adam\n",
      "    Learning  : 0.001\n",
      "    Aggregation     : mkrum\n",
      "    Global Rounds   : 30\n",
      "\n",
      "    Federated parameters:\n",
      "    IID\n",
      "    Fraction of users    : 1\n",
      "    Local Batch size     : 100\n",
      "    Local Epochs         : 5\n",
      "\n",
      "    Malicious parameters:\n",
      "    Attackers            : [3]\n",
      "    Attack Type          : untargeted_med\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "LeNet5(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=44944, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=100, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "| Global Training Round : 1 |\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjeong_umass_edu/.conda/envs/torchgpu/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 1 global rounds:\n",
      "Training Loss : 3.988388169663293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [14:31<7:01:15, 871.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 339.2744 val acc 6.1100\n",
      "\n",
      "Global model Benign Test Accuracy: 6.11% \n",
      "=========================================\n",
      "| Global Training Round : 2 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 2 global rounds:\n",
      "Training Loss : 3.457505524882248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [28:12<6:32:46, 841.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 285.9599 val acc 17.6500\n",
      "\n",
      "Global model Benign Test Accuracy: 17.65% \n",
      "=========================================\n",
      "| Global Training Round : 3 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 3 global rounds:\n",
      "Training Loss : 2.9129060383708705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [42:50<6:26:11, 858.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 333.4916 val acc 19.2300\n",
      "\n",
      "Global model Benign Test Accuracy: 19.23% \n",
      "=========================================\n",
      "| Global Training Round : 4 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 4 global rounds:\n",
      "Training Loss : 2.5431864137468594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [56:26<6:04:45, 841.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 364.3694 val acc 20.1100\n",
      "\n",
      "Global model Benign Test Accuracy: 20.11% \n",
      "=========================================\n",
      "| Global Training Round : 5 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 5 global rounds:\n",
      "Training Loss : 2.2605586678492173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [1:11:07<5:56:35, 855.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 391.2349 val acc 19.1600\n",
      "\n",
      "Global model Benign Test Accuracy: 19.16% \n",
      "=========================================\n",
      "| Global Training Round : 6 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 6 global rounds:\n",
      "Training Loss : 2.048563561382748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [1:24:41<5:36:41, 841.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 415.2630 val acc 19.2900\n",
      "\n",
      "Global model Benign Test Accuracy: 19.29% \n",
      "=========================================\n",
      "| Global Training Round : 7 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 7 global rounds:\n",
      "Training Loss : 1.8861761434357234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [1:38:53<5:23:53, 844.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 417.1126 val acc 18.7800\n",
      "\n",
      "Global model Benign Test Accuracy: 18.78% \n",
      "=========================================\n",
      "| Global Training Round : 8 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 8 global rounds:\n",
      "Training Loss : 1.758122733650463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [1:53:03<5:10:21, 846.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 428.5595 val acc 18.3700\n",
      "\n",
      "Global model Benign Test Accuracy: 18.37% \n",
      "=========================================\n",
      "| Global Training Round : 9 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 9 global rounds:\n",
      "Training Loss : 1.6462146736258672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [2:07:59<5:01:46, 862.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 444.4007 val acc 18.5000\n",
      "\n",
      "Global model Benign Test Accuracy: 18.50% \n",
      "=========================================\n",
      "| Global Training Round : 10 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 10 global rounds:\n",
      "Training Loss : 1.5475223061457677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [2:21:57<4:44:54, 854.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 471.7962 val acc 18.5800\n",
      "\n",
      "Global model Benign Test Accuracy: 18.58% \n",
      "=========================================\n",
      "| Global Training Round : 11 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 11 global rounds:\n",
      "Training Loss : 1.4745535233458988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [2:35:56<4:29:07, 849.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 454.7426 val acc 18.2400\n",
      "\n",
      "Global model Benign Test Accuracy: 18.24% \n",
      "=========================================\n",
      "| Global Training Round : 12 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 12 global rounds:\n",
      "Training Loss : 1.4076850696562213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [2:50:05<4:14:49, 849.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 473.4179 val acc 17.9500\n",
      "\n",
      "Global model Benign Test Accuracy: 17.95% \n",
      "=========================================\n",
      "| Global Training Round : 13 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 13 global rounds:\n",
      "Training Loss : 1.3424336978703595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [3:04:01<3:59:31, 845.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 491.3758 val acc 18.3000\n",
      "\n",
      "Global model Benign Test Accuracy: 18.30% \n",
      "=========================================\n",
      "| Global Training Round : 14 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 14 global rounds:\n",
      "Training Loss : 1.2918311223953878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [3:17:52<3:44:18, 841.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 480.3299 val acc 18.0300\n",
      "\n",
      "Global model Benign Test Accuracy: 18.03% \n",
      "=========================================\n",
      "| Global Training Round : 15 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 15 global rounds:\n",
      "Training Loss : 1.2425081628400256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [3:31:37<3:29:02, 836.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 511.3776 val acc 18.0900\n",
      "\n",
      "Global model Benign Test Accuracy: 18.09% \n",
      "=========================================\n",
      "| Global Training Round : 16 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 16 global rounds:\n",
      "Training Loss : 1.1955007977613215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [3:46:35<3:19:26, 854.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 511.6167 val acc 17.8200\n",
      "\n",
      "Global model Benign Test Accuracy: 17.82% \n",
      "=========================================\n",
      "| Global Training Round : 17 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 17 global rounds:\n",
      "Training Loss : 1.153247471217148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [4:00:41<3:04:39, 852.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 521.9863 val acc 17.3300\n",
      "\n",
      "Global model Benign Test Accuracy: 17.33% \n",
      "=========================================\n",
      "| Global Training Round : 18 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 18 global rounds:\n",
      "Training Loss : 1.1140644122068843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [4:14:59<2:50:48, 854.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 523.9157 val acc 17.5300\n",
      "\n",
      "Global model Benign Test Accuracy: 17.53% \n",
      "=========================================\n",
      "| Global Training Round : 19 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 19 global rounds:\n",
      "Training Loss : 1.0828571520198513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [4:28:44<2:34:57, 845.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 505.1465 val acc 17.0700\n",
      "\n",
      "Global model Benign Test Accuracy: 17.07% \n",
      "=========================================\n",
      "| Global Training Round : 20 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 20 global rounds:\n",
      "Training Loss : 1.052730077682146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [4:45:13<2:28:05, 888.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 519.8961 val acc 17.4200\n",
      "\n",
      "Global model Benign Test Accuracy: 17.42% \n",
      "=========================================\n",
      "| Global Training Round : 21 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 21 global rounds:\n",
      "Training Loss : 1.0258262578342552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [4:59:38<2:12:11, 881.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 524.3985 val acc 17.0900\n",
      "\n",
      "Global model Benign Test Accuracy: 17.09% \n",
      "=========================================\n",
      "| Global Training Round : 22 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 22 global rounds:\n",
      "Training Loss : 1.0004843378420871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [5:12:46<1:53:46, 853.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 523.9314 val acc 17.2000\n",
      "\n",
      "Global model Benign Test Accuracy: 17.20% \n",
      "=========================================\n",
      "| Global Training Round : 23 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 23 global rounds:\n",
      "Training Loss : 0.9752814795584807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [5:26:08<1:37:46, 838.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 528.7131 val acc 17.3800\n",
      "\n",
      "Global model Benign Test Accuracy: 17.38% \n",
      "=========================================\n",
      "| Global Training Round : 24 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 24 global rounds:\n",
      "Training Loss : 0.9501997419906824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [5:39:29<1:22:41, 826.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 540.5860 val acc 16.9800\n",
      "\n",
      "Global model Benign Test Accuracy: 16.98% \n",
      "=========================================\n",
      "| Global Training Round : 25 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 25 global rounds:\n",
      "Training Loss : 0.9309947893751519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [5:52:44<1:08:07, 817.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 525.2994 val acc 17.2800\n",
      "\n",
      "Global model Benign Test Accuracy: 17.28% \n",
      "=========================================\n",
      "| Global Training Round : 26 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 26 global rounds:\n",
      "Training Loss : 0.9119067911288808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [6:05:37<53:35, 803.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 531.7744 val acc 17.1100\n",
      "\n",
      "Global model Benign Test Accuracy: 17.11% \n",
      "=========================================\n",
      "| Global Training Round : 27 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 27 global rounds:\n",
      "Training Loss : 0.8921581876143768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [6:18:41<39:54, 798.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 543.5930 val acc 17.1900\n",
      "\n",
      "Global model Benign Test Accuracy: 17.19% \n",
      "=========================================\n",
      "| Global Training Round : 28 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 28 global rounds:\n",
      "Training Loss : 0.8750729751867024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [6:32:35<26:57, 808.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 537.5212 val acc 16.8500\n",
      "\n",
      "Global model Benign Test Accuracy: 16.85% \n",
      "=========================================\n",
      "| Global Training Round : 29 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 29 global rounds:\n",
      "Training Loss : 0.8575255416814705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [6:47:44<13:58, 838.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 529.7231 val acc 16.5000\n",
      "\n",
      "Global model Benign Test Accuracy: 16.50% \n",
      "=========================================\n",
      "| Global Training Round : 30 |\n",
      "=========================================\n",
      "10 7 3\n",
      " \n",
      "Avg Training Stats after 30 global rounds:\n",
      "Training Loss : 0.8401157678234767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [6:58:20<00:00, 836.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: untargeted_med n_attacker 3 fed_model val loss 540.1229 val acc 16.5200\n",
      "\n",
      "Global model Benign Test Accuracy: 16.52% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Results after 30 global rounds of training:\n",
      "|---- Test Accuracy: 16.52%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "\n",
    "    # define paths\n",
    "    path_project = os.path.abspath('..')\n",
    "    logger = SummaryWriter('../logs')\n",
    "\n",
    "    args = Args()\n",
    "    exp_details(args)\n",
    "\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    for n_attacker in args.mal_clients:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # load dataset and user groups\n",
    "        train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "\n",
    "        # BUILD MODEL\n",
    "        if args.model == 'cnn':\n",
    "            # Convolutional neural netork\n",
    "            if args.dataset == 'mnist':\n",
    "                global_model = CNNMnist(args=args)\n",
    "            elif args.dataset == 'fmnist':\n",
    "                global_model = CNNFashion_Mnist(args=args)\n",
    "            elif args.dataset == 'cifar':\n",
    "                global_model = CNNCifar(args=args)\n",
    "            elif args.dataset == 'cifar100':\n",
    "                global_model = LeNet5(args=args)\n",
    "\n",
    "        elif args.model == 'mlp':\n",
    "            # Multi-layer preceptron\n",
    "            img_size = train_dataset[0][0].shape\n",
    "            len_in = 1\n",
    "            for x in img_size:\n",
    "                len_in *= x\n",
    "                global_model = MLP(dim_in=len_in, dim_hidden=64, dim_out=args.num_classes)\n",
    "        else:\n",
    "            exit('Error: unrecognized model')\n",
    "\n",
    "        # Set the model to train and send it to device.\n",
    "        global_model.to(device)\n",
    "        global_model.train()\n",
    "        print(global_model)\n",
    "\n",
    "        # copy weights\n",
    "        global_weights = global_model.state_dict()\n",
    "\n",
    "        # Training\n",
    "        train_loss, train_accuracy = [], []\n",
    "        val_acc_list, net_list = [], []\n",
    "        cv_loss, cv_acc = [], []\n",
    "        print_every = 1\n",
    "        val_loss_pre, counter = 0, 0\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(args.epochs)):\n",
    "            local_weights, local_losses = [], []\n",
    "            print('=========================================')\n",
    "            print(f'| Global Training Round : {epoch+1} |')\n",
    "            print('=========================================')\n",
    "\n",
    "            global_model.train()\n",
    "            # m = max(int(args.frac * args.num_users), 1)\n",
    "            # idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "\n",
    "            flattened_local_weights = []\n",
    "\n",
    "            \n",
    "            m = max(int(args.frac * args.num_users), 1)\n",
    "            idxs_users = np.random.choice(range(args.num_users), (m - args.mal_clients[0]), replace=False)\n",
    "\n",
    "            for idx in idxs_users:\n",
    "                local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[idx], logger=logger)\n",
    "                w, loss = local_model.update_weights(model=copy.deepcopy(global_model), global_round=epoch)\n",
    "                \n",
    "                local_weights.append(copy.deepcopy(w))\n",
    "                local_losses.append(copy.deepcopy(loss))\n",
    "                \n",
    "                # # get new model\n",
    "                # new_model = copy.deepcopy(global_model)\n",
    "                # new_model.load_state_dict(w)\n",
    "                # acc, _ = local_model.inference(model=new_model)\n",
    "                # print('user {}, loss {:.2f}, acc {:.2f}'.format(idx, loss, 100*acc))\n",
    "\n",
    "                # flatten the local weight (list of ordereddict to a tensor of lists)\n",
    "                flattened_local_weights.append(flatten(w))\n",
    "            flattened_local_weights = torch.tensor(np.array(flattened_local_weights)).to(device)\n",
    "            \n",
    "            malicious_grads = flattened_local_weights\n",
    "            \n",
    "            if n_attacker > 0:\n",
    "                \n",
    "                # Fang attacks (untargeted MPA on mkrum and med)\n",
    "                # agg_grads = torch.mean(malicious_grads, 0)\n",
    "                agg_grads = torch.tensor(flatten(global_weights)).to(device)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                \n",
    "                if args.attack_type == 'untargeted_mkrum':\n",
    "                    malicious_grads = get_malicious_updates_untargeted_mkrum(malicious_grads, agg_grads, deviation, n_attacker)\n",
    "                    \n",
    "                elif args.attack_type == 'untargeted_med':\n",
    "                    malicious_grads = get_malicious_updates_untargeted_med(malicious_grads, deviation, n_attacker)\n",
    "\n",
    "            print(len(malicious_grads),len(flattened_local_weights), n_attacker)\n",
    "            \n",
    "            # update global weights\n",
    "            if args.aggregation == 'fedavg':\n",
    "                agg_weights = fedavg(malicious_grads)\n",
    "            elif args.aggregation == 'krum':\n",
    "                agg_weights, selected_idxs = krum(malicious_grads, n_attacker)\n",
    "            elif args.aggregation == 'mkrum':\n",
    "                agg_weights, selected_idxs = multi_krum(malicious_grads, n_attacker)\n",
    "            elif args.aggregation == 'coomed':\n",
    "                agg_weights = coomed(malicious_grads)\n",
    "            elif args.aggregation == 'bulyan':\n",
    "                agg_weights, selected_idxs = bulyan(malicious_grads, n_attacker)\n",
    "            elif args.aggregation == 'trmean':\n",
    "                agg_weights = tr_mean(malicious_grads, n_attacker)\n",
    "            elif args.aggregation == 'fltrust':\n",
    "                glob_weights = []\n",
    "                glob_weights.append(flatten(global_weights))\n",
    "                agg_weights = fltrust(malicious_grads, glob_weights)\n",
    "\n",
    "            elif args.aggregation == 'flare':\n",
    "                second_last_layer = list(local_weights[0].keys())[-4]\n",
    "                structured_local_weights = [construct_ordered_dict(global_model, flat_weights) for flat_weights in malicious_grads]\n",
    "                plrs = [(each_local[second_last_layer]) for each_local in structured_local_weights]\n",
    "                agg_weights, count_dict = flare(malicious_grads, plrs)\n",
    "                print(f'flare count_dict: {count_dict}')\n",
    "\n",
    "            elif args.aggregation == 'fedcc':\n",
    "                # second_last_layer = list(local_weights[0].keys())[-6]\n",
    "                second_last_layer = list(local_weights[0].keys())[-4]\n",
    "                glob_plr = global_weights[second_last_layer]\n",
    "                # glob_plr = glob_plr.reshape((glob_plr.shape[0]*glob_plr.shape[2], glob_plr.shape[1]*glob_plr.shape[3]))\n",
    "                structured_local_weights = [construct_ordered_dict(global_model, flat_weights) for flat_weights in malicious_grads]\n",
    "                plrs = [(each_local[second_last_layer].reshape((glob_plr.shape[0], glob_plr.shape[1]))) for each_local in structured_local_weights]\n",
    "                agg_weights, selected_idxs = fed_cc(local_weights, glob_plr, 'kernel')\n",
    "                print(f'fed_cc Selected idx: {selected_idxs}')\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Unknown aggregation strategy: {}'.format(args.aggregation))\n",
    "\n",
    "\n",
    "            # reshape the flattened global weights into the ordereddict\n",
    "            global_weights = construct_ordered_dict(global_model, agg_weights)\n",
    "\n",
    "            # update global weights\n",
    "            global_model.load_state_dict(global_weights)\n",
    "\n",
    "            loss_avg = sum(local_losses) / len(local_losses)\n",
    "            train_loss.append(loss_avg)\n",
    "\n",
    "            # # Calculate avg training accuracy over all users at every epoch\n",
    "            # list_acc, list_loss = [], []\n",
    "            # global_model.eval()\n",
    "            # for c in range(args.num_users):\n",
    "            #     local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[c], logger=logger)\n",
    "            #     acc, loss = local_model.inference(model=global_model)\n",
    "            #     list_acc.append(acc)\n",
    "            #     list_loss.append(loss)\n",
    "            # train_accuracy.append(sum(list_acc)/len(list_acc))\n",
    "\n",
    "            # print global training loss after every 'i' rounds\n",
    "            if (epoch+1) % print_every == 0:\n",
    "                print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
    "                print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "                test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "                \n",
    "                print('%s: %s n_attacker %d fed_model val loss %.4f val acc %.4f' \\\n",
    "                      %(args.aggregation, args.attack_type, n_attacker, test_loss, 100*test_acc))\n",
    "                print('\\nGlobal model Benign Test Accuracy: {:.2f}% '.format(100*test_acc))\n",
    "                \n",
    "    # Test inference after completion of training\n",
    "    test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "\n",
    "    print(f' \\n Results after {args.epochs} global rounds of training:')\n",
    "    # print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "    print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
    "\n",
    "#     # Saving the objects train_loss and train_accuracy:\n",
    "#     file_name = '../save/objects/{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}].pkl'.\\\n",
    "#         format(args.dataset, args.model, args.epochs, args.frac, args.iid, args.local_ep, args.local_bs)\n",
    "\n",
    "#     with open(file_name, 'wb') as f:\n",
    "#         pickle.dump([train_loss, train_accuracy], f)\n",
    "\n",
    "#     print('\\n Total Run Time: {0:0.4f}'.format(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e3f4c-4fe2-4959-b7a7-f567db7c2a26",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torchgpu)",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
